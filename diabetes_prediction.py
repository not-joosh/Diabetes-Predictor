# -*- coding: utf-8 -*-
"""Diabetes Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Za5Eqee3oQvBwyYcwgndkkNuroR6EHvU

Importing Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data Collection and Analysis.
PIMA Diabetes Dataset
"""

# loaing the diabetes dataset to a pandas DataFrame
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

# printing the first 5 rows of tthe dataset
diabetes_dataset.head()

# number of rows and columns in this dataset
diabetes_dataset.shape

# getting the statistical measures of the data
diabetes_dataset.describe()

# Taking Outcome values, checking how many 0's and 1's
diabetes_dataset['Outcome'].value_counts()

"""0 ---> Non Diabetic

1 ---> Diabetic
"""

# Getting the mean for these both of these values...
diabetes_dataset.groupby('Outcome').mean()

# Seperating Data on labels... Spitting. Axis = 1 if wee are dropping colmn, axis = 0 if we drop a row
X = diabetes_dataset.drop(columns = 'Outcome', axis = 1)
Y = diabetes_dataset['Outcome']

print(X)

print(Y)

# Data Standardization | This is to establish a specific range for the ml model to make better predictions
scaler = StandardScaler()

scaler.fit(X) # Passing in our data to transform

standardizedData = scaler.transform(X)
# scaler.fit_transform(X) <-- Single Step.

print(standardizedData)

"""Now, our model can make better predictions because the values are in similar range. It is between 0 and 1 now.

"""

X = standardizedData
print(X)
print(Y)

"""**Train Test Split**

"""

# X is the data,Y is the label.
# Test Size is 0.2, 20% of data test data. The 80% is used as training Data.
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 2)

print(X.shape, X_train.shape, X_test.shape)

"""**Training the Machine Model**"""

# Trainig the Model
classifier = svm.SVC(kernel='linear')

classifier.fit(X_train, Y_train)

"""**Moel Evaluation**


Accuracy Score

"""

# accuracy score on the training data
X_trainPrediction = classifier.predict(X_train)
trainingDataAccuracy = accuracy_score(X_trainPrediction, Y_train) # Comparing X_train to Y_train

print('Accuracy score: ', trainingDataAccuracy * 100, '%')

X_testPrediction = classifier.predict(X_test)
testDataAccuracy = accuracy_score(X_testPrediction, Y_test)

print('Accuracy score: ', testDataAccuracy * 100, '%')

"""**Making Predicitive System**

"""

# Expected is Diabetic: 1
# 5,166,72,19,175,25.8,0.587,51 | 1
input_data = (5,166,72,19,175,25.8,0.587,51)

# Changing input data into numpy array.
input_data_as_numpy_arr = np.asarray(input_data)

# reshape the array as w are predicting for one instance
# rsehape will tell the model that we are going to need prediction
# for only one data point
input_data_reshape = input_data_as_numpy_arr.reshape(1, -1) # we are not giving 786 examples, just 1 example

# in training, we standardizedd the data, o we must do the same here.
# We will continue here to standardize the data.
std_data = scaler.transform(input_data_reshape)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction)
if(prediction[0] == 0):
  print('The person is not diabetic.')
else:
  print('The person is diabetic.')

"""The model successfully predicted that the peron is diabetic."""